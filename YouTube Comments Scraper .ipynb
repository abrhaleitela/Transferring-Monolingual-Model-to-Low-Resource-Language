{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Download all comments of a given YouTube channel! This will generate a txt file with all comments of all videos in a given channel\n",
    "\"\"\"\n",
    "\n",
    "from apiclient.errors import HttpError\n",
    "from apiclient.discovery import build\n",
    "\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\"\n",
    "DEVELOPER_KEY = \"YOUR YOUTUBE DEVELOPER KEY\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all comments of a given video_id with out replies\n",
    "def get_comments(youtube, video_id, comments):\n",
    "    threads = []\n",
    "    results = youtube.commentThreads().list(\n",
    "        part=\"snippet\",\n",
    "        videoId=video_id,\n",
    "        textFormat=\"plainText\",\n",
    "    ).execute()\n",
    "\n",
    "    #Get the first set of comments\n",
    "    for item in results[\"items\"]:\n",
    "        threads.append(item)\n",
    "        comment = item[\"snippet\"][\"topLevelComment\"]\n",
    "        text = comment[\"snippet\"][\"textDisplay\"]\n",
    "        comments.append(' '.join(text.replace('\\n',' ').split()))\n",
    "\n",
    "    #Keep getting comments from the following pages\n",
    "    while (\"nextPageToken\" in results):\n",
    "        results = youtube.commentThreads().list(\n",
    "        part=\"snippet\",\n",
    "        videoId=video_id,\n",
    "        pageToken=results[\"nextPageToken\"],\n",
    "        textFormat=\"plainText\",\n",
    "        ).execute()\n",
    "        for item in results[\"items\"]:\n",
    "            threads.append(item)\n",
    "            comment = item[\"snippet\"][\"topLevelComment\"]\n",
    "            text = comment[\"snippet\"][\"textDisplay\"]\n",
    "            comments.append(' '.join(text.replace('\\n',' ').split()))\n",
    "\n",
    "    return threads\n",
    "\n",
    "#Get all replies of a comment and returns all comments including previously downloaded\n",
    "def get_comment_replies(youtube, parent_comment_id, comments):\n",
    "    results = youtube.comments().list(\n",
    "        part=\"snippet\",\n",
    "        parentId=parent_comment_id,\n",
    "        textFormat=\"plainText\"\n",
    "    ).execute()\n",
    "\n",
    "    for item in results[\"items\"]:\n",
    "        text = item[\"snippet\"][\"textDisplay\"]\n",
    "        comments.append(text)\n",
    "\n",
    "    return comments\n",
    "\n",
    "#Gets all videos in a channel\n",
    "def get_channel_videos(channel_id):\n",
    "    \n",
    "    res = youtube.channels().list(id=channel_id, \n",
    "                                  part='contentDetails').execute()\n",
    "    playlist_id = res['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    \n",
    "    videos = []\n",
    "    next_page_token = None\n",
    "    \n",
    "    while True:\n",
    "        res = youtube.playlistItems().list(playlistId=playlist_id, \n",
    "                                           part='snippet', \n",
    "                                           maxResults=50,\n",
    "                                           pageToken=next_page_token).execute()\n",
    "        videos += res['items']\n",
    "        next_page_token = res.get('nextPageToken')\n",
    "        \n",
    "        if next_page_token is None:\n",
    "            break\n",
    "    \n",
    "    return videos\n",
    "\n",
    "\n",
    "#Read data from given txt file and return all video_ids as an array\n",
    "def get_accessed_videos(ACCESSED_VIDEOS_PATH):\n",
    "    with open(ACCESSED_VIDEOS_PATH, \"r\", encoding=\"utf-8\") as file:\n",
    "        vid_ids = file.readlines()\n",
    "    return [video_id.replace('\\n','') for video_id in vid_ids]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/accessed_videos.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-3e82ae2c023a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0myoutube\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYOUTUBE_API_SERVICE_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYOUTUBE_API_VERSION\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeveloperKey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDEVELOPER_KEY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mACCESSED_VIDEOS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_accessed_videos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mACCESSED_VIDEOS_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mvideos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_channel_videos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannel_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mvideos_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-2554e712d712>\u001b[0m in \u001b[0;36mget_accessed_videos\u001b[1;34m(ACCESSED_VIDEOS_PATH)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;31m#Read data from given txt file and return all video_ids as an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_accessed_videos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mACCESSED_VIDEOS_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mACCESSED_VIDEOS_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mvid_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvideo_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvid_ids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/accessed_videos.txt'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":    \n",
    "    #Copy the channel id you want scrap and assign it to variable \"channel_id\"\n",
    "    channel_id = 'UCO1u_DqxUJQJ7xSUqbXMDHQ'\n",
    "    \n",
    "    OUTPUTFILE = \"data/output_file.txt\"\n",
    "    ACCESSED_VIDEOS_PATH = \"data/accessed_videos.txt\"\n",
    "    \n",
    "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=DEVELOPER_KEY)\n",
    "    \n",
    "    ACCESSED_VIDEOS = get_accessed_videos(ACCESSED_VIDEOS_PATH)\n",
    "    videos = get_channel_videos(channel_id)\n",
    "    videos_ids = []\n",
    "    for video in videos:\n",
    "        videos_ids.append(video['snippet']['resourceId']['videoId'])\n",
    "        #if you want to filter by video upload date\n",
    "        #if video['snippet']['publishedAt'].startswith((\"2019-12\",\"2020-01\",\"2019-11\",\"2020-02\")):\n",
    "            #video_ids.append(video['snippet']['resourceId']['videoId'])\n",
    "        \n",
    "    output_file = open(OUTPUTFILE, \"w\", encoding=\"utf-8\")\n",
    "    i = length = 0\n",
    "    for video_id in videos_ids:\n",
    "        i += 1\n",
    "        if video_id not in ACCESSED_VIDEOS:\n",
    "            try:            \n",
    "                comments = []\n",
    "                video_comments = get_comments(youtube, video_id, comments)\n",
    "                #If you want to get replies in a comment uncomment the following 2 lines: (note it might cause your API limit)\n",
    "                #for comment in video_comments:\n",
    "                    #get_comment_replies(youtube, comment[\"id\"], comments)\n",
    "\n",
    "                output_file.write('\\n'.join(comments))\n",
    "                output_file.write('\\n')\n",
    "                length += len(comments)\n",
    "                print(\"Video %d/%d:\\tVID:%s\\tcurrent Video's Comments: %d\\tTotal comments: %d\" %(i, len(videos_ids), video_id ,len(video_comments),length) )\n",
    "                \n",
    "            except HttpError as e:\n",
    "                if not \"disabled comments\" in str(e.content):\n",
    "                    print(\"An HTTP error %d occurred:\\n%s\" % (e.resp.status, e.content))\n",
    "                    print(\"\\n\\n\\n------------\\n\\n\\n\")\n",
    "                    print(\"Not finished... Your API KEY has exceeded the limit\")\n",
    "                    print(\"Id\" + video_id)\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Comments disabled.... Could not download comments from %s\", video_id)\n",
    "                \n",
    "        else:\n",
    "             print(\"Video %d/%d:\\tTotal comments: %d \\tVIDEO COMMENTS ALREADY SCRAPED: %s\" %(i, len(videos_ids),length,video_id))\n",
    "        ACCESSED_VIDEOS.append(video_id)\n",
    "    output_file.close()\n",
    "    #Save all video ids already downloaded to a file \n",
    "    with open(ACCESSED_VIDEOS_PATH, 'w') as file:\n",
    "        file.write('\\n'.join(ACCESSED_VIDEOS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
